{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1O-e2CcfZ0_1"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7iXwXYvZ0_5",
    "outputId": "8bfa2b81-63d2-4545-8f0e-0c70001ce6ea"
   },
   "outputs": [],
   "source": [
    "# import tensorflow and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# import other necessary preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NUBCWLCJZ0_-"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(XTrain, yTrain), (XTest, yTest) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AlhY6F6vZ1AA"
   },
   "source": [
    "## Visualize data and preprocess it\n",
    "\n",
    "Now, we will analyse the data and see how to train it, with what model to train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nBmcl5gjZ1AB",
    "outputId": "22fcfe7d-51ed-4bee-a2d0-61ab9401df7f"
   },
   "outputs": [],
   "source": [
    "print(\"[+] XTrain shape: \", XTrain.shape, \"\\n[+] yTrain shape: \", yTrain.shape)\n",
    "print(\"[+] XTest shape: \", XTest.shape, \"\\n[+] yTest shape: \", yTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZvq-5lOZ1AE"
   },
   "source": [
    "As we can see, the data has a lot of problem, especially on the label side. So first lets see the label data\n",
    "\n",
    "### 1. Analysis of Y data\n",
    "Lets print and see how is our Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2N9DWfY9Z1AF",
    "outputId": "5ea8c11e-efaf-4984-cdd3-c1bfa97c936d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EbgLilsIZ1AJ"
   },
   "source": [
    "We can clearly see that it is of a look-up number. So, we need a lookup table to retrieve the label. This is the lookup table\n",
    "<table width = 50%>\n",
    "  <tbody><tr>\n",
    "    <th>Label</th>\n",
    "    <th>Class</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td> \n",
    "  </tr>\n",
    "</tbody></table>\n",
    "\n",
    "Now lets make a lookup table based on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjGWuV3_Z1AK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7a3heCi6Z1AM"
   },
   "source": [
    "### 2. Image processing - X data\n",
    "\n",
    "lets fix the image and see how to set it for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLgzxGHbZ1AN",
    "outputId": "6b915438-7005-4b89-a488-3967cf0a7dc3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9k0LezTZ1AQ"
   },
   "outputs": [],
   "source": [
    "# The problem here is that we have 0 - 255 values but this will cause our math to get way too huge numbers \n",
    "# and causes a lot of problem when training with its inconsistent results \n",
    "# lets normalize image data to be b/n 0 - 1 for better learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gWJ6D7RVZ1AU",
    "outputId": "60d8d027-3e9c-4c2b-fbb6-57d30b36611d"
   },
   "outputs": [],
   "source": [
    "# lets display and check\n",
    "plt.figure(figsize = (10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(XTrain[i], cmap = plt.cm.binary)\n",
    "    plt.xlabel(class_names[yTrain[i]], color = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZ_83XKRZ1AW"
   },
   "source": [
    "## 3. One - hot encoder\n",
    "Our Y-data is categorical from 10 classes. so now we will make the Y data into a one hot encoded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GqsNYpuZ1AX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H3Jv8HvyZ1AZ"
   },
   "source": [
    "## Final Data after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_fDe0gDZ1Aa",
    "outputId": "703c9bef-0a6e-43ac-a358-86831fba7f47"
   },
   "outputs": [],
   "source": [
    "print(\"[+] XTrain shape: \", XTrain.shape, \"\\n[+] yTrain shape: \", yTrain.shape)\n",
    "print(\"[+] XTest shape: \", XTest.shape, \"\\n[+] yTest shape: \", yTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJmJv_sHZ1Ad"
   },
   "source": [
    "## Model Building\n",
    "Building a NN model is very easy with tensorflow 2.0 after its merge with keras. Now, we can just plug and play with the keras Sequential builder or we can predefine our model graph and run it as a model with keras Model builder.\n",
    "We will look at both ways now.\n",
    "\n",
    "### 1. Sequential Builder\n",
    "The sequential builder works like this. First, we start with a empty model, then just like lego bricks, we add them one after the other just like that on the fly. Finally, we fit the model for our dataset with `model.fit()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHrnkz_dZ1Ae"
   },
   "outputs": [],
   "source": [
    "## Sequential model example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsMNAQWWZ1Ag"
   },
   "outputs": [],
   "source": [
    "## Adding layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RhSOL1TfZ1Aj",
    "outputId": "b1503219-d992-480b-e4ff-4ae8073466ee"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7EiHJvxZ1Ap"
   },
   "source": [
    "### 2. Model Builder\n",
    "The model builder is a traditional tf method of building neural network model. We first define the entire model as a computation graph, Then we instantiate the model with the `keras.Model` class. Now, we use the same `model.fit()` to fit the data and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "htT4e3BBZ1Ap"
   },
   "outputs": [],
   "source": [
    "## Define your graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xvWyPcykZ1As",
    "outputId": "40e5c11d-3404-496e-fe67-5d6a1cdad28d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hfM83u6yZ1Av"
   },
   "source": [
    "## Compile the model\n",
    "Regardless of using Sequential or Model builder technic. We need to compile the model and specify the loss function and mention the optimizer either GradientDescent or Adam or RMSprop or Adagrad. Also we mention metrics like accuracy or Dice or F1 Score or IOU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ryZtDezZ1Av"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yF27o2y4Z1Ay"
   },
   "source": [
    "## Train the model\n",
    "Now we will train the model. Lets use our Model Builder model to train our model but this is your choice. Just use `model.fit(<X data>, <Y data>, epochs = <no. of epochs>)` function to fit the train data for our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BGTANt6Z1Az",
    "outputId": "c1b465ed-2b75-44b4-ced6-3d5a77fef7e6"
   },
   "outputs": [],
   "source": [
    "model.fit(XTrain, yTrain, validation_data = (XTest, yTest), epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNyRajvYZ1A2"
   },
   "source": [
    "## Evaluate the model\n",
    "Time to evaluate the model we have built. To do this, we have `model.evaluate()` function to evaluate the data. It gives back the (loss, metrics) values. We can use that to check our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-0wmcB6Z1A2",
    "outputId": "5ab71bce-797f-4f8f-b486-da43d042a12b"
   },
   "outputs": [],
   "source": [
    "testLoss, testAccuracy = model.evaluate(XTest, yTest)\n",
    "print(\"[+] Test Loss: %.4f\\n[+] Test Accuracy: %.2f%%\" %(testLoss,testAccuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_MgFQK_KZ1A5"
   },
   "source": [
    "## Predictions\n",
    "You can make predictions in keras model using `model.predict()`.  Lets do it and see what we are getting for one test input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG43dYu2Z1A6"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vS3gjdiMZ1A9",
    "outputId": "996b9bb5-548f-438d-f4d8-e65a841532ec"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WW3xOzKPZ1BA"
   },
   "source": [
    "The prediction gave us a vector. This vector is actually of size 10 out of which each element are the probability of that class for the corresponding inputs. We need to only get the index of that element which has the highest probability as that is our output. \n",
    "\n",
    "This is achieved by using the `np.argmax` function\n",
    "\n",
    "Then we need to just use the lookup table for our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aw8zY7ciZ1BB",
    "outputId": "591018f3-421a-4967-bdd0-a0ad8a0d6095"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t7JBDJFhZ1BE"
   },
   "source": [
    "Lets check our original output `yTest[0]` just in case to see how our model predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PgOMr_e-Z1BE",
    "outputId": "1ea96276-9350-46f5-a41a-3e9d62ad2564"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXpYELXaZ1BI"
   },
   "source": [
    "## Lookup\n",
    "Now, we will lookup the values from our lookup table for our prediction and put it up with the image for the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NmBjoSLuZ1BL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1. Basic Classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
